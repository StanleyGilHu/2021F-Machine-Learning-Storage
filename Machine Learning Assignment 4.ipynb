{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "a) What is Conditional probability, Marginal probability and Joint probability? Write their mathematical formulas and give one example each. [5 pts]\n",
    "\n",
    "b) Explain what is Baye’s rule with the formula and what is prior, posterior, likelihood and marginal probability in the Baye’s rule. [10 pts]\n",
    "\n",
    "c) What is Naive Bayes algorithm and how is related or derived or inspired from Bayes rule? [5 pts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "    Conditional Probatility is the probability or likelihood of an event occuring or a classification being valid, with the value modified by being restricted to another subset of data with another event of classification used to define the subset, effectively measuring or correlating the two sets of data. The representative formula is P(B|A) = P(B and A)/P(A), or the probability of B occuring given the probabilty of A occuring.\n",
    "\n",
    "    Marginal Probability is the calculation of the probabilty of an occurance in a dataset, indpendant of any other considerations or labels of data outside of those within the category being measured. It can be represented as P(A).\n",
    "    \n",
    "    Joint probability is the calculation of the probability of two occurances occuring at the same time, based on analysis of their previous occurances and meetings, and disregarding other conditions or variables. The equation for this is P（A and B)\n",
    "    \n",
    "b)\n",
    "\n",
    "    Baye's rule, also known as Baye's theorem, can be represented by the equation:\n",
    "    \n",
    "    P(A|B) = P(B|A) * P(A) /P(B)\n",
    "\n",
    "    Where A and B are events and the probability of event B (P(B)), also known as the \"Marginalization\", is greater than zero. P(A) is known as the \"Prior\", or the initial probabiilty that A is true, from across the entire dataset, which is being used as the basis for further investigation as to whether B specifically influences A occuring. The likelihood is the probability that B occurs (P(B)) given that A occurs, using the information provided. Both P(B) and P(A) are unmodified with no conditions or prepositions other than the data set as a whole, and are known as marginal probabilities. The Posterior is the desired information and end result of Bayes Theorem, (P(A|B)), the calculated probability that A occurs given that B also occurs. \n",
    "\n",
    "c\n",
    "\n",
    "    Naives Bayes Algorithms, also known as Naive Bayes classifiers, are a family of classifying algorithms which assign labels to items without considering the relationships between the variables that items, judging each variable value seperately to determine the category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Perform Naive Bayes algorithm on the below dataset in python in which you can classify test example weather a Red Domestic SUV is stolen or not as shown in 2.2. [10 pts]\n",
    "\n",
    "Hints and Explanation:\n",
    "convert 1(Table 1),2.1 into a csv then load a csv file or you can prepare your dataframe from 2.1 dataset. [As i posted the text for 2.1,Table 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import numpy as np \n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Red, sports, domesticated, are all set to 0?\n",
    "#Not stolen, 0, stolen 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Only two types of each variable, so assuming binary/Bernoulli/boolean distribution and algorithm\n",
    "\n",
    "X1 = pd.read_csv('svm.csv')\n",
    "\n",
    "Y=X1.target_class\n",
    "X1 = X1.drop(columns=['Example', 'Stolen'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y, test_size=0.25, random_state=0)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X1, Y)\n",
    "BernoulliNB()\n",
    "print(clf.predict(X1[2:3]))\n",
    "#0,1,0\n",
    "p2Arr = [0,1,0]\n",
    "print(clf.predict([p2Arr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Perform Naive Bayes algorithm on the below problem3.csv dataset in python. [70Pts].\n",
    "\n",
    "    1. Print out Accuracy Score, Confusion matrix for both training and test set.\n",
    "\n",
    "    2. Print True Positives(TP),True Negatives(TN), False Positives(FP) ,False Negatives(FN) for both train and test sets.\n",
    "\n",
    "    3. Visualize confusion matrix with heatmap plot for both train and test sets.\n",
    "\n",
    "    4. Print the classification report (precision,recall or Sensitivity and f1-score) for both test and train dataset\n",
    "\n",
    "    5. As the naive bayes algorithm is based on probabilities, please calculate class probabilities of each item in the test set. Then visualize the histogram of class probabilities of each class of target variable separately (Our Target Variable is Income which has two unique classe, so two histograms )\n",
    "\n",
    "    Hints and Explanation: 1.Perform Exploratory data analysis on the entire dataset (finding missing values or any special characters, converting categorical values to numerical values ..etc,), 2. Don’t remove the missing value row instead use the methods discussed in class like column mean,mode ..etc to impute. 3. Split train and test in the ratio of 70 and 30. 4. For calculating the class probabilites one can use the sklearn module directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0             0             0              13   United-States   <=50K  \n",
       "1             0             0              40   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40            Cuba   <=50K  \n",
       "4             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = pd.read_csv('problem3.csv')\n",
    "#Y = X[labels]\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "names = X2.columns\n",
    "print(names)\n",
    "adf1len=len(X2)\n",
    "X3 = X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[' ?', ' Federal-gov', ' Local-gov', ' Never-worked', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay']\n",
      "[]\n",
      "[' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college']\n",
      "[]\n",
      "[' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed']\n",
      "[' ?', ' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving']\n",
      "[' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife']\n",
      "[' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White']\n",
      "[' Female', ' Male']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia']\n",
      "[' <=50K', ' >50K']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        age          workclass  fnlwgt    education  education_num  \\\n",
       "0       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "1       38            Private  215646      HS-grad              9   \n",
       "2       53            Private  234721         11th              7   \n",
       "3       28            Private  338409    Bachelors             13   \n",
       "4       37            Private  284582      Masters             14   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32555   27            Private  257302   Assoc-acdm             12   \n",
       "32556   40            Private  154374      HS-grad              9   \n",
       "32557   58            Private  151910      HS-grad              9   \n",
       "32558   22            Private  201490      HS-grad              9   \n",
       "32559   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "1                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "2       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "3       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "4       Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32555   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32556   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32557              Widowed        Adm-clerical       Unmarried   White   \n",
       "32558        Never-married        Adm-clerical       Own-child   White   \n",
       "32559   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male             0             0              13   United-States   \n",
       "1         Male             0             0              40   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3       Female             0             0              40            Cuba   \n",
       "4       Female             0             0              40   United-States   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32555   Female             0             0              38   United-States   \n",
       "32556     Male             0             0              40   United-States   \n",
       "32557   Female             0             0              40   United-States   \n",
       "32558     Male             0             0              20   United-States   \n",
       "32559   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32555   <=50K  \n",
       "32556    >50K  \n",
       "32557   <=50K  \n",
       "32558   <=50K  \n",
       "32559    >50K  \n",
       "\n",
       "[32560 rows x 15 columns]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#X3[~X3.columns.str.contains(\"?\")]\n",
    "\n",
    "\n",
    "X3.replace('Male', 0)\n",
    "X3.replace('Female', 1)\n",
    "X3.replace('<=50K', 0)\n",
    "X3.replace('>50K', 1)\n",
    "\n",
    "X3.replace({\"Male\": 0, \"Female\": 1})\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "#X3[X3.native_country != '?']\n",
    "\n",
    "\n",
    "for columnname in names:\n",
    "    #this line is supposed to drop all rows with ? string.\n",
    "    X3 = X3[~X3[columnname].isin([\"?\"])]\n",
    "    #X3[X3[columnname].str.contains(\"?\")==False]\n",
    "    templist = []\n",
    "    for item in X3[columnname]:\n",
    "        if item not in templist:\n",
    "            if not isinstance(item, int):\n",
    "                templist.append(item)\n",
    "    templist = sorted(templist)\n",
    "    print(templist)\n",
    "    for elem in templist:\n",
    "        replaVar=templist.index(elem)\n",
    "        X3.replace(elem, replaVar)\n",
    "        X3.replace({elem: replaVar})\n",
    "        \n",
    "\n",
    "                   \n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "#Get list of all var names, then replace.\n",
    "#The Gaussian NB requires every element to be a float, not a string. Converting them to an int in this case, I hope.\n",
    "#Where if it's not on the list, it's added to the list.\n",
    "#later, the function goes through the list and replaces the df value with the index value serving as the int. \n",
    "\n",
    "X3.head\n",
    "\n",
    "\n",
    "#Not sure why it's not working? Double checked the sklearn documentation, so far as I'm aware I'm replacing it perfectly fine?\n",
    "\n",
    "#big issues is in the replace. Everything else doesn't return any errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.to_csv('problem3v2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Unnamed: 0  age          workclass  fnlwgt    education  education_num  \\\n",
       "0               0   50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "1               1   38            Private  215646      HS-grad              9   \n",
       "2               2   53            Private  234721         11th              7   \n",
       "3               3   28            Private  338409    Bachelors             13   \n",
       "4               4   37            Private  284582      Masters             14   \n",
       "...           ...  ...                ...     ...          ...            ...   \n",
       "32555       32555   27            Private  257302   Assoc-acdm             12   \n",
       "32556       32556   40            Private  154374      HS-grad              9   \n",
       "32557       32557   58            Private  151910      HS-grad              9   \n",
       "32558       32558   22            Private  201490      HS-grad              9   \n",
       "32559       32559   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "1                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "2       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "3       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "4       Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32555   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32556   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32557              Widowed        Adm-clerical       Unmarried   White   \n",
       "32558        Never-married        Adm-clerical       Own-child   White   \n",
       "32559   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male             0             0              13   United-States   \n",
       "1         Male             0             0              40   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3       Female             0             0              40            Cuba   \n",
       "4       Female             0             0              40   United-States   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32555   Female             0             0              38   United-States   \n",
       "32556     Male             0             0              40   United-States   \n",
       "32557   Female             0             0              40   United-States   \n",
       "32558     Male             0             0              20   United-States   \n",
       "32559   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32555   <=50K  \n",
       "32556    >50K  \n",
       "32557   <=50K  \n",
       "32558   <=50K  \n",
       "32559    >50K  \n",
       "\n",
       "[32560 rows x 16 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4 = pd.read_csv('problem3v2.csv')\n",
    "\n",
    "X4.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "names = X2.columns\n",
    "adf1len=len(X2)\n",
    "\n",
    "X2A = X4.drop(columns=['income'])\n",
    "X2B = X4.income\n",
    "#Assuming that income is target\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(X2A, X2B, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "#I'm guessing Gaussian Naive bayes formula for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' Private'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-167a881cebf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrainresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \"\"\"\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' Private'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "\n",
    "\n",
    "clf2.fit(x2_train, y2_train)\n",
    "\n",
    "trainresult = clf2.predict(x2_train)\n",
    "accuracy_score(trainresult, y2_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf2.fit(x2_test, y2_test)\n",
    "trainresult = clf2.predict(x2_test)\n",
    "accuracy_score(trainresult, y2_train)\n",
    "\n",
    "\n",
    "#print(clf2.predict(x2_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSS(actual, predict):\n",
    "    TP = 0 #True Positive\n",
    "    FP = 0 #False Positive\n",
    "    TN = 0 #True negative\n",
    "    FN = 0 #False Negative\n",
    "\n",
    "    for i in range(len(predict)): \n",
    "        if actual[i]==predict[i]==1:\n",
    "           TP += 1\n",
    "        if predict[i]==1 and actual[i]!=predict[i]:\n",
    "           FP += 1\n",
    "        if actual[i]==predict[i]==0:\n",
    "           TN += 1\n",
    "        if predict[i]==0 and actual[i]!=predict[i]:\n",
    "           FN += 1\n",
    "    print(TP)\n",
    "    print(FP)\n",
    "    print(TN)\n",
    "    print(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2, TP, FP, TN, FN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "clf2.fit(x2_train, y2_train)\n",
    "trainresult1 = clf2.predict(x2_train)\n",
    "print(TSS(y2_train, trainresult1))\n",
    "\n",
    "cf_matrix = confusion_matrix(y2_train, trainresult1)\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "clf2.fit(x2_test, y2_test)\n",
    "trainresult2 = clf2.predict(x2_test)\n",
    "print(TSS(y2_testn, trainresult2))\n",
    "\n",
    "cf_matrix = confusion_matrix(y2_test, trainresult2)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y2_train, trainresult1, target_names=target_names))\n",
    "\n",
    "print(classification_report(y2_test, trainresult2, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
